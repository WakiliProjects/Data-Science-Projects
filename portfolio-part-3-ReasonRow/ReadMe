Analysis:

The presented work establishes a train and test model for both the logistic regression and K-Nearest Neighbors (KNN) models, which are essential components in machine learning.
This approach helps evaluate the performance of each model and allows us to predict and assess how accurate the data is.
The dataset was split so that 90% was used for training while 10% was used for testing. The sum of the training and testing values should always equal one.

Exploration:

• Cleansing the data was the first step, which involved checking for null values and removing any missing entries.
• Categorical values such as gender, review, category, and item were converted to numerical values using OrdinalEncoder, since machine learning models cannot process raw string values.
• While evaluating the data, the correlation between the newly converted numerical features and the target variable rating was studied to understand the strength of these relationships.
• The dataset was split once for both the logistic regression and KNN models to allow consistent evaluation of performance across both models.
• Training the logistic regression model helped predict the observed values and find the best-fitting weights for the data.
• For the KNN model, training was especially useful as it can perform well even when labelled data is limited or costly to obtain. It provided relatively accurate predictions based on the training samples.
• After training, predictions were made and the accuracy of each model was measured. Accuracy values are bounded between 0 and 1, where 1 indicates perfect accuracy.
• Tuning the hyperparameter K in the KNN model was the next step. This involved adjusting the number of neighbors used to see how it affected the accuracy. The accuracy only changed by around 0.01, showing minor sensitivity to K value.
• Finally, the results were visualised. Visualisation helped identify trends and better understand model performance.
A graph was used to show that as the K value increased, the training error also increased, while the testing error decreased until both began to flatten out, indicating a stabilisation in performance.

Conclusion:

Through the exploration and analysis of this dataset, the project successfully applied both logistic regression and KNN models to handle the given tasks.
The exercise deepened understanding of how prediction models behave, especially when adjusting parameters like K in KNN, and demonstrated the value of visualisation in interpreting machine learning outcomes.
